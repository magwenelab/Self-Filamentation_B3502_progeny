{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bring in needed mods\n",
    "import numpy as np, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List to checksum\n",
    "checkpath = '/home/croth/SELFFILM/FASTQ/Sun_6673_210202B6.checksum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Checksum</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Fastq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21f0e2cb074b218f6f5c1ec1810fe6a8</td>\n",
       "      <td>Sun_6673_210202B6/SS_20201123_A34_S50_L001_R2_...</td>\n",
       "      <td>SS_20201123_A34_S50_L001_R2_001.fastq.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5b7bb09edca67e158dae83f9147f300c</td>\n",
       "      <td>Sun_6673_210202B6/SS_20201123_B09_S69_L001_R2_...</td>\n",
       "      <td>SS_20201123_B09_S69_L001_R2_001.fastq.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d3d2a8db32a4151b1ea880064ed0ee1d</td>\n",
       "      <td>Sun_6673_210202B6/SS_20201123_A36_S52_L001_R2_...</td>\n",
       "      <td>SS_20201123_A36_S52_L001_R2_001.fastq.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f6c98a47477bab400387ef1a7c604ee8</td>\n",
       "      <td>Sun_6673_210202B6/SEC_20201123_01_S1_L001_R2_0...</td>\n",
       "      <td>SEC_20201123_01_S1_L001_R2_001.fastq.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9e777f5c9260f5f8af8329da2cc438ab</td>\n",
       "      <td>Sun_6673_210202B6/SS_20201123_A12_S28_L001_R1_...</td>\n",
       "      <td>SS_20201123_A12_S28_L001_R1_001.fastq.gz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Checksum  \\\n",
       "0  21f0e2cb074b218f6f5c1ec1810fe6a8   \n",
       "1  5b7bb09edca67e158dae83f9147f300c   \n",
       "2  d3d2a8db32a4151b1ea880064ed0ee1d   \n",
       "3  f6c98a47477bab400387ef1a7c604ee8   \n",
       "4  9e777f5c9260f5f8af8329da2cc438ab   \n",
       "\n",
       "                                            Filename  \\\n",
       "0  Sun_6673_210202B6/SS_20201123_A34_S50_L001_R2_...   \n",
       "1  Sun_6673_210202B6/SS_20201123_B09_S69_L001_R2_...   \n",
       "2  Sun_6673_210202B6/SS_20201123_A36_S52_L001_R2_...   \n",
       "3  Sun_6673_210202B6/SEC_20201123_01_S1_L001_R2_0...   \n",
       "4  Sun_6673_210202B6/SS_20201123_A12_S28_L001_R1_...   \n",
       "\n",
       "                                      Fastq  \n",
       "0  SS_20201123_A34_S50_L001_R2_001.fastq.gz  \n",
       "1  SS_20201123_B09_S69_L001_R2_001.fastq.gz  \n",
       "2  SS_20201123_A36_S52_L001_R2_001.fastq.gz  \n",
       "3   SEC_20201123_01_S1_L001_R2_001.fastq.gz  \n",
       "4  SS_20201123_A12_S28_L001_R1_001.fastq.gz  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checksums = pd.read_csv(checkpath,header=None,sep=' ')\n",
    "checksums.dropna(axis=1,how='all',inplace=True)\n",
    "checksums.columns = ['Checksum','Filename']\n",
    "checksums['Fastq'] = [s.split('/')[-1] for s in checksums.Filename]\n",
    "checksums.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "B20s = ['SS_20201123_H99_03_S9_L001_R1_001.fastq.gz','SS_20201123_H99_03_S9_L001_R2_001.fastq.gz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H99s = sorted([f for f in checksums.Fastq if len(f.split(\"H99\")) == 2 and f not in B20s])\n",
    "len(H99s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastqs = [ f for f in checksums.Fastq if f.split('_')[0] == 'SS' and f not in H99s]\n",
    "len(fastqs)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SS_20201123_A01_S17_L001_R1_001.fastq.gz',\n",
       " 'SS_20201123_A01_S17_L001_R2_001.fastq.gz',\n",
       " 'SS_20201123_A02_S18_L001_R1_001.fastq.gz',\n",
       " 'SS_20201123_A02_S18_L001_R2_001.fastq.gz',\n",
       " 'SS_20201123_A03_S19_L001_R1_001.fastq.gz',\n",
       " 'SS_20201123_A03_S19_L001_R2_001.fastq.gz']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(fastqs)[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = list(np.unique([f.split('_R')[0] for f in fastqs]))[::-1]\n",
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SS_20201123_H99_03_S9_L001',\n",
       " 'SS_20201123_B12_S72_L001',\n",
       " 'SS_20201123_B11_S71_L001',\n",
       " 'SS_20201123_B10_S70_L001',\n",
       " 'SS_20201123_B09_S69_L001']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set path to reference on big duck\n",
    "refpath = '/analysis/CROTH/Self-Filamentation_B3502_progeny/REF/FungiDB-48_CneoformansJEC21_Genome.fasta'\n",
    "\n",
    "## set data path\n",
    "datapath = '/analysis/CROTH/SELFFILAM/'\n",
    "\n",
    "## set sam path \n",
    "sampath = datapath+'SAM/'\n",
    "\n",
    "## set bam path\n",
    "#bampath = datapath+'BAM/'\n",
    "\n",
    "## set bamaddrg path\n",
    "addrgpath = '/home/croth/bin/./bamaddrg -b'\n",
    "\n",
    "## set command\n",
    "command = 'bwa mem -a -M %s %s %s | samtools view -F 4 -b | samtools sort -o %s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gather sample ends \n",
    "ends = np.unique([a.split('_R')[-1] for a in fastqs])\n",
    "\n",
    "## Check work paired end so should be 2\n",
    "assert len(ends) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make bam paths\n",
    "bams = [sampath+s+'-sm.bam' for s in samples]\n",
    "\n",
    "## check work\n",
    "assert len(np.unique(bams)) == len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## construct bam commands and take them ordred by size\n",
    "bwa = np.array([command%(refpath,datapath+f+'_R'+ends[0],\n",
    "                         datapath+f+'_R'+ends[1],bams[i]+'\\n\\n') \n",
    "                for i,f in enumerate(samples)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bwa mem -a -M /analysis/CROTH/Self-Filamentation_B3502_progeny/REF/FungiDB-48_CneoformansJEC21_Genome.fasta /analysis/CROTH/SELFFILAM/SS_20201123_H99_03_S9_L001_R1_001.fastq.gz /analysis/CROTH/SELFFILAM/SS_20201123_H99_03_S9_L001_R2_001.fastq.gz | samtools view -F 4 -b | samtools sort -o /analysis/CROTH/SELFFILAM/SAM/SS_20201123_H99_03_S9_L001-sm.bam\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## view first command\n",
    "bwa[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split progeny samples across 4 files\n",
    "nfiles = 4\n",
    "\n",
    "filenames = './run%s_bwa.sh'\n",
    "for i in range(nfiles):\n",
    "    filename = filenames%i\n",
    "    \n",
    "    open(filename,'w').writelines(bwa[i::nfiles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gather unique sample names\n",
    "samples_temp = [s.split('_')[2] for s in bams]\n",
    "samples = [s if s != 'H99' else 'B20' for s in samples_temp]\n",
    "samplen = [s.split('_')[-2] for s in bams]\n",
    "\n",
    "## Check work\n",
    "assert len(np.unique(samples)) == len(samples)\n",
    "assert len(np.unique(samplen)) == len(samplen)\n",
    "assert len(np.unique(samples)) == len(np.unique(samplen))\n",
    "\n",
    "## Print first few\n",
    "samples[:5],samplen[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/croth/bin/./bamaddrg -b /analysis/CROTH/SELFFILAM/SAM/SS_20201123_H99_03_S9_L001-sm.bam -s B20 -r S9.0 > /analysis/CROTH/SELFFILAM/SAM/SS_20201123_H99_03_S9_L001-sm-rg.bam\n",
      "gzip /analysis/CROTH/SELFFILAM/SAM/SS_20201123_H99_03_S9_L001-sm.bam\n",
      "\n",
      "\n",
      "/home/croth/bin/./bamaddrg -b /analysis/CROTH/SELFFILAM/SAM/SS_20201123_B12_S72_L001-sm.bam -s B12 -r S72.1 > /analysis/CROTH/SELFFILAM/SAM/SS_20201123_B12_S72_L001-sm-rg.bam\n",
      "gzip /analysis/CROTH/SELFFILAM/SAM/SS_20201123_B12_S72_L001-sm.bam\n",
      "\n",
      "\n",
      "/home/croth/bin/./bamaddrg -b /analysis/CROTH/SELFFILAM/SAM/SS_20201123_B11_S71_L001-sm.bam -s B11 -r S71.2 > /analysis/CROTH/SELFFILAM/SAM/SS_20201123_B11_S71_L001-sm-rg.bam\n",
      "gzip /analysis/CROTH/SELFFILAM/SAM/SS_20201123_B11_S71_L001-sm.bam\n",
      "\n",
      "\n",
      "/home/croth/bin/./bamaddrg -b /analysis/CROTH/SELFFILAM/SAM/SS_20201123_B10_S70_L001-sm.bam -s B10 -r S70.3 > /analysis/CROTH/SELFFILAM/SAM/SS_20201123_B10_S70_L001-sm-rg.bam\n",
      "gzip /analysis/CROTH/SELFFILAM/SAM/SS_20201123_B10_S70_L001-sm.bam\n",
      "\n",
      "\n",
      "/home/croth/bin/./bamaddrg -b /analysis/CROTH/SELFFILAM/SAM/SS_20201123_B09_S69_L001-sm.bam -s B09 -r S69.4 > /analysis/CROTH/SELFFILAM/SAM/SS_20201123_B09_S69_L001-sm-rg.bam\n",
      "gzip /analysis/CROTH/SELFFILAM/SAM/SS_20201123_B09_S69_L001-sm.bam\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Make bamaddrg commands\n",
    "## adds the read groups to the merged bam files\n",
    "## zip the old bam files too\n",
    "## eventually we will delete these\n",
    "add_commands = ['%s %s -s %s -r %s > %s\\ngzip %s\\n\\n'%(\n",
    "                addrgpath,\n",
    "                b,\n",
    "                samples[i],\n",
    "                samplen[i]+'.%s'%i,\n",
    "                '-rg.'.join(b.split('.')),\n",
    "                b) for i,b in enumerate(bams)]\n",
    "\n",
    "## Check work\n",
    "assert len(np.unique(add_commands)) == len(add_commands)\n",
    "\n",
    "## View a few of these commands\n",
    "for c in add_commands[:5]:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write bamaddrg commands, \n",
    "## here we are going to make twice as many files \n",
    "## to run a total of 8 scripts in paralle\n",
    "run_addrg = './run%s_addrg.sh'\n",
    "for i in range(nfiles):\n",
    "    open(run_addrg%i,'w').writelines(add_commands[i::nfiles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e99f91a18d62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 1 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write merged bam files\n",
    "merged_bams = np.unique([bampath+s.split('_L00')[0]+'.bam' for s in samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gather the sam file names\n",
    "sams = np.unique([b.split('_L00')[0] for b in bams])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write merge commands\n",
    "merged = ['samtools merge %s %s %s\\n\\n'%(\n",
    "    merged_bams[i] ,s+'_L001-sm.bam',s+'_L002-sm.bam') \n",
    "          for i,s in enumerate(sams)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## View first few commands\n",
    "merged[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How many merged files are there?\n",
    "assert len(merged) == len(samples)/2\n",
    "\n",
    "len(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write merge commands\n",
    "run_merge = '../MERGE/run%s_merge.sh'\n",
    "for i in range(nfiles):\n",
    "    open(run_merge%i,'w').writelines(merged[i::nfiles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make bamaddrg commands\n",
    "## adds the read groups to the merged bam files\n",
    "## zip the old bam files too\n",
    "## eventually we will delete these\n",
    "add_commands = ['%s %s -s %s -r %s > %s\\ngzip %s\\n\\n'%(\n",
    "                addrgpath,\n",
    "                b,\n",
    "                b.split('/')[-1].split('_')[0],\n",
    "                b.split('_')[-1].split('.ba')[0]+'.%s'%i,\n",
    "                '-rg.'.join(b.split('.')),\n",
    "                b) for i,b in enumerate(merged_bams)]\n",
    "\n",
    "## Check work\n",
    "assert len(np.unique(add_commands)) == len(add_commands)\n",
    "\n",
    "## View a few of these commands\n",
    "add_commands[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What are the unique two digits after PMY?\n",
    "np.unique([s.split('_')[0][3:5] for s in samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write bamaddrg commands, \n",
    "## here we are going to make twice as many files \n",
    "## to run a total of 8 scripts in paralle\n",
    "run_addrg = '../ADDRG/run%s_addrg.sh'\n",
    "for i in range(nfiles*2):\n",
    "    open(run_addrg%i,'w').writelines(add_commands[i::2*nfiles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bamrg = ['-rg.'.join(b.split('.')) for b in merged_bams]\n",
    "bamrg[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write samtools index file\n",
    "samix = ['samtools index %s\\n'%b for b in bamrg]\n",
    "open('../SAMIX/run_samtools_ix.sh','w').writelines(samix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Five samples seemed to fail, b/c I missed called samtools ix\n",
    "## Write command to fix these 5 that failed\n",
    "## Write the five that failed\n",
    "failed = ['PMY2557','PMY2601','PMY2701','PMY2801','PMY2901']\n",
    "\n",
    "## write remove command to destory old versions\n",
    "failed_bamrg = ['rm %s\\n'%a \n",
    "                for a in bamrg if a.split('/')[-1].split('_')[0] in failed] \n",
    "assert len(failed_bamrg) == len(failed)\n",
    "\n",
    "## Unzip bam files\n",
    "failed_unzip = ['gunzip %s.bam.gz\\n'%a.split('-rg')[0] \n",
    "                for a in bamrg if a.split('/')[-1].split('_')[0] in failed] \n",
    "assert len(failed_unzip) == len(failed)\n",
    "\n",
    "## Gather the add read group commands\n",
    "failed_addrg = [a for a in add_commands if a.split(' ')[4] in failed]\n",
    "assert len(failed_addrg) == len(failed)\n",
    "\n",
    "## Reindex\n",
    "failed_samix = ['samtools index %s\\n'%a \n",
    "                for a in bamrg if a.split('/')[-1].split('_')[0] in failed]\n",
    "assert len(failed_samix) == len(failed)\n",
    "\n",
    "## Write to file\n",
    "open('../FAILED/reruns.sh','w').writelines(failed_bamrg+failed_unzip+failed_addrg+failed_samix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write out list of bams\n",
    "open('../listofbams.txt','w').writelines('\\n'.join(bamrg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES\n",
    "You will need to take the .sh files and run chmod +x *.sh to make them executables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
